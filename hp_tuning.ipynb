{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "mlp_venv",
   "display_name": "mlp_venv",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from concat_stations import concat_files\n",
    "from data_prep import get_param_dist\n",
    "from rf_optimize import evaluate\n",
    "\n",
    "import json\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn.model_selection import RandomizedSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(42600, 30)\n(42600,)\n"
     ]
    }
   ],
   "source": [
    "# insert and prepare the data\n",
    "\n",
    "# Prepare the data\n",
    "\n",
    "full_data = concat_files()\n",
    "for i in full_data.columns:\n",
    "    full_data = full_data[full_data[i].notna()]\n",
    "full_data = pd.get_dummies(full_data) # Turn weekday into 1-hot encoding\n",
    "feature_cols = list(full_data.drop('bikes', axis = 1).columns)\n",
    "\n",
    "y = np.array(full_data['bikes']) # array for target variable\n",
    "X = full_data[feature_cols] # Features\n",
    "X = np.array(X) # Turn into numpy array\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed: 10.3min\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed: 49.3min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed: 124.9min finished\n",
      "{'n_estimators': 400, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': None, 'bootstrap': False}\n"
     ]
    }
   ],
   "source": [
    "# Get model parameters\n",
    "random_grid = get_param_dist()\n",
    "\n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "\n",
    "# Search for the optimum hyperparameters - n_iter is the number of different combinations we want to try, n_iter is the number of fods for cross validation\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "\n",
    "# Train the model on training data\n",
    "rf_random.fit(X_train, y_train)\n",
    "\n",
    "print(rf_random.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "r2 error with best paramters 0.8126948026732219\n"
     ]
    }
   ],
   "source": [
    "best_random = rf_random.best_estimator_\n",
    "mae, r2_score = evaluate(best_random, X_test, y_test)\n",
    "\n",
    "print(\"r2 error with best paramters {}\".format(r2_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'n_estimators': 400, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': None, 'bootstrap': False}\n"
     ]
    }
   ],
   "source": [
    "print(rf_random.best_params_)\n",
    "best_params = rf_random.best_params_\n",
    "with open('output_metrics.txt', 'a') as file:\n",
    "     file.write(json.dumps(best_params)) # use `json.loads` to do the reverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = {\"model_type\": \"rf_best_params\", \"r2_score\": r2_score, \"mae\": mae} \n",
    "with open('output_metrics.txt', 'a') as file:\n",
    "     file.write(json.dumps(data)) # use `json.loads` to do the reverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('output_metrics.txt', 'a') as file:\n",
    "     file.write(json.dumps(best_params)) # use `json.loads` to do the reverse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "RandomForestRegressor(bootstrap=False, max_features='sqrt', n_estimators=400,\n                      random_state=42)\n"
     ]
    }
   ],
   "source": [
    "print(best_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}